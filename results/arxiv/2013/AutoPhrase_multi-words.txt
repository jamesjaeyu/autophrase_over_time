0.9669173913	feature extraction
0.9664298305	genetic algorithm
0.9624980100	data mining
0.9608297968	expert systems
0.9593362216	pattern recognition
0.9590787646	convex optimization
0.9584717087	neural network
0.9575127500	feature selection
0.9563827814	bayesian network
0.9557856334	probability distributions
0.9551693856	speech recognition
0.9550176527	gaussian process
0.9546523069	dynamic programming
0.9545075341	fuzzy logic
0.9513023551	bayesian inference
0.9504569291	image processing
0.9499924023	big data
0.9466042640	machine translation
0.9464708258	gradient descent
0.9460604126	knowledge base
0.9457590469	supervised learning
0.9417388484	conditional probability
0.9404630740	reinforcement learning
0.9397564471	deep learning
0.9384042455	natural language
0.9327568337	artificial intelligence
0.9303903661	neural networks
0.9292510242	monte carlo
0.9252878743	state space
0.9251065695	dimensionality reduction
0.9213146236	evolutionary algorithm
0.9205592084	gene expression
0.9172026028	machine learning
0.9170479512	random variables
0.9110800454	model selection
0.9016646273	object recognition
0.8972445024	belief functions
0.8968922624	online learning
0.8968087387	graphical models
0.8958369892	matrix factorization
0.8923153180	probabilistic reasoning
0.8907815075	computational complexity
0.8907728474	dictionary learning
0.8882661186	influence diagrams
0.8877751762	optimization problem
0.8870584070	probability distribution
0.8862033765	face recognition
0.8809954401	belief networks
0.8795667520	decision theoretic
0.8795505405	metric learning
0.8785394905	evidential reasoning
0.8766396055	knowledge representation
0.8765522227	deep neural
0.8735234257	markov decision
0.8725554628	conditional independence
0.8667091652	answer set programming
0.8636487773	object detection
0.8604816442	belief network
0.8604506240	probabilistic logic
0.8604114929	logic programs
0.8603574067	spectral clustering
0.8602900204	probabilistic inference
0.8536144058	optimization problems
0.8458672035	matrix completion
0.8453971640	rule based
0.8411031899	bayesian networks
0.8409693936	sparse coding
0.8324602224	sample complexity
0.8319673570	decision making
0.8273303796	answer set
0.8269500041	convergence rate
0.8257795900	high level
0.8243940266	component analysis
0.8195961646	data set
0.8133540089	support vector
0.8111132517	armed bandit
0.8079576901	objective function
0.7974901799	dempster shafer theory
0.7908868373	em algorithm
0.7894166706	semi supervised
0.7875366427	data sets
0.7863688158	dempster shafer
0.7766504087	low level
0.7744912751	multi class
0.7743545090	computational cost
0.7649036546	data analysis
0.7612441971	influence diagram
0.7530147591	image classification
0.7481082166	high dimensional
0.7456082166	large scale
0.7450538063	artificial neural
0.7408116074	multi armed
0.7374670656	low dimensional
0.7337763935	hidden markov
0.7252076055	low rank
0.6858322716	recent years
0.6805459332	small number
0.6736799137	vector machine
0.6486445532	language processing
0.6467672485	empirical results
0.6464119747	real world
0.6426012304	decision processes
0.6245842512	based approach
0.6219888687	experimental results
0.5968960820	paper describes
0.5943053431	inthis paper
0.5648396641	set programming
0.5478628872	graph based
0.5453703596	paper presents
0.5268137897	model parameters
0.5071796925	based systems
0.5059288016	model based
0.4883086584	shafer theory
0.4822678794	conference on uncertainty
0.4806794750	knowledge based
0.4772537289	learning algorithm
0.4581892130	proposed method
0.4473556548	computer vision
0.4467071043	least squares
0.4222894565	under uncertainty
0.4196532342	training data
0.4179845584	clustering algorithm
0.4067855041	paper proposes
0.3895773135	real data
0.3865992805	algorithm based
0.3806102476	based methods
0.3784892034	k means
0.3779608172	learning algorithms
0.3762099516	reasoning about
0.3751787721	time series
0.3735637170	synthetic and real
0.3547236088	second order
0.3539952514	polynomial time
0.3418920204	first order
0.3388171316	results demonstrate
0.3088918492	non convex
0.3073010845	large number of
0.3055258293	dimensional data
0.3042719226	real time
0.3021258180	a wide range
0.2947029185	learning methods
0.2905492627	faster than
0.2823968213	proposed algorithm
0.2813545233	proposed approach
0.2663684706	widely used
0.2642833053	the proposed approach
0.2533113498	wide range of
0.2529395504	previous work
0.2515972001	experimental results show
0.2462535706	non linear
0.2455439175	art methods
0.2450839876	et al
0.2431275538	large number
0.2364494897	different types
0.2342059248	world data
0.2277196684	a bayesian network
0.2253787114	the proposed algorithm
0.2246501471	this paper describes
0.2232348703	the proposed method
0.2210985211	this paper presents
0.2196402503	into account
0.2190869527	this paper proposes
0.2166835877	dealing with
0.2062634484	this paper introduces
0.2051965420	viewed as
0.2042363818	a hybrid
0.2026410167	a new approach
0.1999720303	the art methods
0.1894158749	an efficient
0.1892168960	relies on
0.1846810530	relationship between
0.1817313650	a large number
0.1788110531	an application
0.1772390849	a novel approach
0.1726858924	depends on
0.1726586197	at least
0.1708790242	based on
0.1703469609	the other hand
0.1673875903	this article
0.1614387708	rely on
0.1605744651	bag of
0.1588131651	rather than
0.1575949137	novel approach
0.1562979202	many applications
0.1533700566	an agent
0.1528956419	more efficient
0.1452636293	new algorithm
0.1435728824	inspired by
0.1413142683	better than
0.1384750699	does not
0.1377781835	leading to
0.1361563886	thenumber of
0.1343070926	more general
0.1334750699	do not
0.1331105486	algorithm based on
0.1318308999	experiments on
0.1278185949	deal with
0.1277321889	this paper
0.1262568780	focus on
0.1262064267	an alternative
0.1254072697	well known
0.1245440780	represented by
0.1239113518	an extension
0.1205492756	an important
0.1136489930	results show
0.1132677352	number of
0.1130259190	a novel
0.1116778741	the art
0.1101861523	leads to
0.1101775338	state of
0.1066981691	kind of
0.1060674028	lead to
0.1052245293	experiments show
0.1037930492	not only
0.1032610605	to overcome
0.1020434015	a new
0.1015027855	to solve
0.1013240343	to compute
0.1006544162	the existence of
0.0975356115	this problem
0.0963948969	the original
0.0963503802	bounds on
0.0942413171	an algorithm
0.0905701696	the latter
0.0901027186	to select
0.0897537604	an approach
0.0896119964	an image
0.0894778804	to identify
0.0889657829	algorithm for
0.0884159378	new approach
0.0871627131	but also
0.0862432419	variety of
0.0845820963	family of
0.0844435255	to deal with
0.0840064352	compared with
0.0837436736	capable of
0.0829281076	such as
0.0829195908	this approach
0.0826678463	in addition
0.0818426734	the structure of
0.0818426734	the size of
0.0818426734	the probability of
0.0812481281	with respect to
0.0810648956	the value of
0.0798426734	the accuracy of
0.0798426734	the case of
0.0794132399	to learn
0.0790947742	as well as
0.0790648956	the use of
0.0788913533	the presence of
0.0788426734	the application of
0.0788090600	by means of
0.0786620886	conference on
0.0772871178	a class of
0.0768839363	to determine
0.0768426734	the concept of
0.0768426734	the process of
0.0768426734	the efficiency of
0.0762871178	the context of
0.0762871178	the field of
0.0758090707	associated with
0.0754871504	method for
0.0753425453	to predict
0.0746102564	this method
0.0742871178	the task of
0.0738907088	to generate
0.0737821028	along with
0.0733732499	by applying
0.0732947141	new method
0.0732770298	advantage of
0.0727633083	in order to
0.0725090809	in thispaper
0.0724505597	due to
0.0717792980	bound on
0.0696130096	this work
0.0689245725	a new method
0.0685774500	the state of
0.0684987133	our approach
0.0682867537	with respect
0.0682763247	advances in
0.0679080215	to detect
0.0674155391	combined with
0.0669828173	more than
0.0657345236	to implement
0.0647345236	to extract
0.0647216416	in terms of
0.0640372929	a single
0.0637283047	presence of
0.0635060383	framework for
0.0633495582	to reduce
0.0629107820	obtained by
0.0622687592	according to
0.0622585924	a generalization of
0.0615732002	a variety of
0.0611232152	to train
0.0610703059	the final
0.0607965047	the performance of
0.0607965047	the problem of
0.0606103660	definition of
0.0599909794	the proposed
0.0587358986	a set of
0.0583945578	approach to
0.0582374196	implementation of
0.0571283622	the relationship between
0.0566540503	information from
0.0563732812	set of
0.0563066299	model for
0.0562372592	able to
0.0560259282	approach for
0.0560057850	the number of
0.0549627351	the effectiveness of
0.0547983162	the development of
0.0545495015	the purpose of
0.0542365771	respect to
0.0541316495	the quality of
0.0539745930	achieved by
0.0532427606	the ability to
0.0531552062	range of
0.0526355345	a number of
0.0520777729	analysis of
0.0517765449	the same
0.0516948186	to build
0.0502571502	this study
0.0497717200	the complexity of
0.0494438610	the existence
0.0494336575	amount of
0.0492435224	of magnitude
0.0485396780	version of
0.0477045265	notion of
0.0476591883	close to
0.0474258635	uncertainty in
0.0473795773	the past
0.0471143862	to obtain
0.0463872790	a method for
0.0456314151	combination of
0.0453507400	the presence
0.0448420340	to construct
0.0448342593	a simple
0.0446406989	a measure
0.0437267217	part of
0.0436731372	the main
0.0433293872	the literature
0.0423203647	the expected
0.0422961408	the effect
0.0418420340	to handle
0.0416327933	role in
0.0408045107	other hand
0.0396397233	the set of
0.0396397233	the analysis of
0.0395287484	a general
0.0394957912	success of
0.0388786014	similar to
0.0387221596	the idea
0.0387213064	the input
0.0379577284	relative to
0.0376509090	the number
0.0371194382	a combination of
0.0368276626	performance of
0.0367609232	to find
0.0358459014	to evaluate
0.0356397233	a framework for
0.0354456117	in practice
0.0347677935	known as
0.0345928342	the goal
0.0331397233	the notion of
0.0328459014	to represent
0.0327097229	used as
0.0322485403	to perform
0.0320332864	collection of
0.0318459014	to address
0.0312511320	complexity of
0.0310659014	to achieve
0.0307764027	to produce
0.0307727143	subset of
0.0306121766	to improve
0.0303998329	basis for
0.0299871347	a method
0.0296374440	a large
0.0296267080	quality of
0.0294663974	a small
0.0294293116	the problem
0.0290002548	suitable for
0.0280848798	in terms
0.0275067593	tool for
0.0274746039	the relationship
0.0272317321	in contrast
0.0271313518	a subset
0.0269228087	aims to
0.0265817114	an optimal
0.0263080301	to provide
0.0258812728	to capture
0.0256946039	the development
0.0255800528	purpose of
0.0248283995	as well
0.0238459014	to estimate
0.0233826432	existence of
0.0221612868	to increase
0.0216946039	the ability
0.0216308251	a variety
0.0216028453	a special
0.0215552795	development of
0.0214815929	to deal
0.0203992089	a wide
0.0193159525	a set
0.0193134721	effectiveness of
0.0185920267	a given
0.0180733388	a number
0.0177834260	to make
0.0173714942	a few
0.0167834260	for example
0.0164517539	in particular
0.0163741738	ability to
0.0163612706	the effectiveness
0.0127760523	to compare
0.0107760523	to develop
0.0079142127	well as
0.0079035517	need to
