{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901595e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import Levenshtein as Lv\n",
    "import time\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf9813",
   "metadata": {},
   "source": [
    "## Loading in AutoPhrase and phrasal segmentation results dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88215c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoPhrase results dataframe\n",
    "fp_phrases = '../results/dblp-v10-grouped/phrases.csv'\n",
    "phrases = pd.read_csv(fp_phrases, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8582fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processed phrasal segmentation results dataframe\n",
    "infolder = '../results/dblp-v10-grouped'\n",
    "subfolders = glob(infolder + '/*.csv')\n",
    "subfolders = list(filter(lambda x: 'segmented' in x, subfolders))\n",
    "seg = pd.DataFrame(columns=['Phrases', 'Year', 'Num Phrases'])\n",
    "for fp in subfolders:\n",
    "    df = pd.read_csv(fp, index_col=0)\n",
    "    df = df.dropna()\n",
    "    df['Num Phrases'] = df.apply(lambda x: len(x['Phrases'].split(',')), axis=1)\n",
    "    #df = df.drop('Phrases', axis=1)\n",
    "    seg = seg.append(df, ignore_index=True)\n",
    "seg = seg.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152780d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe add code for creating counts dictionary if it can be used with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9856524",
   "metadata": {},
   "source": [
    "## Integrating phrase quality with phrasal segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18258994",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg['Phrases'] = seg['Phrases'].map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05701671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "      <th>Year</th>\n",
       "      <th>Num Phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[paper, wheatstone, bridge, tangent, triangle,...</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[numerical integration, differential equations...</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fur]</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[computing, computing, amplifier, high, amplif...</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[operations research, journal, operations rese...</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548126</th>\n",
       "      <td>[research, fi, indoor, location-based service ...</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548127</th>\n",
       "      <td>[icts, eliminating, gender, entrepreneurship, ...</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548128</th>\n",
       "      <td>[infinite horizon, inventory, model, general, ...</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548129</th>\n",
       "      <td>[infrared, technology, deep-space, radiation, ...</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548130</th>\n",
       "      <td>[net, power output, exergy, organic, rankine c...</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2548131 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Phrases       Year  \\\n",
       "0        [paper, wheatstone, bridge, tangent, triangle,...  1950-1959   \n",
       "1        [numerical integration, differential equations...  1950-1959   \n",
       "2                                                    [fur]  1950-1959   \n",
       "3        [computing, computing, amplifier, high, amplif...  1950-1959   \n",
       "4        [operations research, journal, operations rese...  1950-1959   \n",
       "...                                                    ...        ...   \n",
       "2548126  [research, fi, indoor, location-based service ...  2015-2017   \n",
       "2548127  [icts, eliminating, gender, entrepreneurship, ...  2015-2017   \n",
       "2548128  [infinite horizon, inventory, model, general, ...  2015-2017   \n",
       "2548129  [infrared, technology, deep-space, radiation, ...  2015-2017   \n",
       "2548130  [net, power output, exergy, organic, rankine c...  2015-2017   \n",
       "\n",
       "        Num Phrases  \n",
       "0                14  \n",
       "1                 6  \n",
       "2                 1  \n",
       "3                 8  \n",
       "4                 5  \n",
       "...             ...  \n",
       "2548126          44  \n",
       "2548127          18  \n",
       "2548128          12  \n",
       "2548129          51  \n",
       "2548130          34  \n",
       "\n",
       "[2548131 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3f1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_qualities(x):\n",
    "    \"\"\"\n",
    "    Helper function to process the segmentation.csv files\n",
    "    Only keeps quality phrases (multi >= 0.5, single >= 0.8)\n",
    "    Obtains the phrase quality of each phrase by matching with phrases.csv\n",
    "    \"\"\"\n",
    "    x = x['Phrases']\n",
    "    out_phrases = []\n",
    "    out_quality = []\n",
    "    for phrase in x:\n",
    "        # Phrase will not show up in the phrases df if the quality is too low\n",
    "        # We only kept multi >= 0.5 and single >= 0.8\n",
    "        # NOTE: Potential issue with phrase having dashes in seg when they don't in phrases\n",
    "        #       (i.e. user-controlled vs. user controlled)\n",
    "        match = phrases[phrases['Phrase'] == phrase]\n",
    "        # NOTE: Doesn't do a year match for the phrase quality\n",
    "        if len(match) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            out_phrases.append(phrase)\n",
    "            out_quality.append(match['Phrase Quality'].values[0])\n",
    "    return out_phrases, out_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c93b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_phrases(x):\n",
    "    \"\"\"\n",
    "    Helper function for the segmentation results to remove any low quality phrases\n",
    "    \"\"\"\n",
    "    x = x['Phrases']\n",
    "    out = []\n",
    "    for phrase in x:\n",
    "        match = phrases[phrases['Phrase'] == phrase]\n",
    "        if len(match) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            out.append(phrase)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7822128b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010-2014    872492\n",
       "2005-2009    651846\n",
       "2015-2017    430039\n",
       "2000-2004    309663\n",
       "1995-1999    144373\n",
       "1990-1994     71394\n",
       "1985-1989     32741\n",
       "1980-1984     16836\n",
       "1975-1979      9377\n",
       "1970-1974      5541\n",
       "1965-1969      2642\n",
       "1960-1964       853\n",
       "1950-1959       334\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74af58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010-2014    87153\n",
       "2005-2009    65341\n",
       "2015-2017    43003\n",
       "2000-2004    30905\n",
       "1995-1999    14397\n",
       "1990-1994     7152\n",
       "1985-1989     3268\n",
       "1980-1984     1656\n",
       "1975-1979      981\n",
       "1970-1974      580\n",
       "1965-1969      251\n",
       "1960-1964       94\n",
       "1950-1959       32\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg.sample(frac=0.1)['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e8518ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_normal = pd.DataFrame(columns=['Phrase', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d620c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seg.apply(filter_phrases, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc74a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip(*seg.apply(find_qualities, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5161846b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "      <th>Num Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23440</th>\n",
       "      <td>0.557913</td>\n",
       "      <td>user controlled</td>\n",
       "      <td>1995-1999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45754</th>\n",
       "      <td>0.716653</td>\n",
       "      <td>user controlled</td>\n",
       "      <td>2000-2004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93921</th>\n",
       "      <td>0.792673</td>\n",
       "      <td>user controlled</td>\n",
       "      <td>2005-2009</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195600</th>\n",
       "      <td>0.748656</td>\n",
       "      <td>user controlled</td>\n",
       "      <td>2010-2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281156</th>\n",
       "      <td>0.715213</td>\n",
       "      <td>user controlled</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality           Phrase       Year  Num Words\n",
       "23440         0.557913  user controlled  1995-1999          2\n",
       "45754         0.716653  user controlled  2000-2004          2\n",
       "93921         0.792673  user controlled  2005-2009          2\n",
       "195600        0.748656  user controlled  2010-2014          2\n",
       "281156        0.715213  user controlled  2015-2017          2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The segmentation phrases have some phrases with dashes like \"user-controlled\"\n",
    "phrases[phrases['Phrase'] == 'user controlled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c6bae8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user-controlled'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[^A-Za-z0-9- ]+', '', 'user-controlled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7eedcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user controlled'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to replace dashes (and potentially other chars) with a space\n",
    "re.sub(r'[-]+', ' ', 'user-controlled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1b90c",
   "metadata": {},
   "source": [
    "# Analysis of AutoPhrase results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b50e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_uniquebyyear = '../results/dblp-v10/phrases.csv'\n",
    "#fp_unique = '../results/dblp-v10-phrases-unique.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7533f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from year 1968 - years before had too little training data\n",
    "# We only kept multi-word phrases above 0.6 and single-word above 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e88f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains the phrases unique overall (no duplicates)\n",
    "# un_all = pd.read_csv(fp_unique, index_col=0)\n",
    "# un_all = un_all[un_all['Year'] >= 1968]\n",
    "# un_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8e3f2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.946833</td>\n",
       "      <td>context free</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.890167</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.909000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.896000</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.993000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238718</th>\n",
       "      <td>0.600501</td>\n",
       "      <td>practical implementation</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238719</th>\n",
       "      <td>0.600363</td>\n",
       "      <td>next generation</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238720</th>\n",
       "      <td>0.600185</td>\n",
       "      <td>deep convolutional neural</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238721</th>\n",
       "      <td>0.600087</td>\n",
       "      <td>network nodes</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238722</th>\n",
       "      <td>0.600061</td>\n",
       "      <td>received signal</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238701 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality                     Phrase  Year\n",
       "20            0.946833               context free  1968\n",
       "21            0.890167               time sharing  1968\n",
       "22            0.909000               context free  1969\n",
       "23            0.896000               time sharing  1969\n",
       "24            0.993000               context free  1970\n",
       "...                ...                        ...   ...\n",
       "238718        0.600501   practical implementation  2017\n",
       "238719        0.600363            next generation  2017\n",
       "238720        0.600185  deep convolutional neural  2017\n",
       "238721        0.600087              network nodes  2017\n",
       "238722        0.600061            received signal  2017\n",
       "\n",
       "[238701 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contains the phrases unique by year (there can be duplicates across years)\n",
    "uby = pd.read_csv(fp_uniquebyyear, index_col=0)\n",
    "uby = uby[uby['Year'] >= 1968]\n",
    "uby = uby.dropna()\n",
    "uby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8506ca3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.946833</td>\n",
       "      <td>context free</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.890167</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.909000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.896000</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.993000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238718</th>\n",
       "      <td>0.600501</td>\n",
       "      <td>practical implementation</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238719</th>\n",
       "      <td>0.600363</td>\n",
       "      <td>next generation</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238720</th>\n",
       "      <td>0.600185</td>\n",
       "      <td>deep convolutional neural</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238721</th>\n",
       "      <td>0.600087</td>\n",
       "      <td>network nodes</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238722</th>\n",
       "      <td>0.600061</td>\n",
       "      <td>received signal</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228615 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality                     Phrase  Year\n",
       "20            0.946833               context free  1968\n",
       "21            0.890167               time sharing  1968\n",
       "22            0.909000               context free  1969\n",
       "23            0.896000               time sharing  1969\n",
       "24            0.993000               context free  1970\n",
       "...                ...                        ...   ...\n",
       "238718        0.600501   practical implementation  2017\n",
       "238719        0.600363            next generation  2017\n",
       "238720        0.600185  deep convolutional neural  2017\n",
       "238721        0.600087              network nodes  2017\n",
       "238722        0.600061            received signal  2017\n",
       "\n",
       "[228615 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keeps the phrases that show up multiple times across years (so we can look for trends)\n",
    "uby_dups = uby.copy()\n",
    "uby_dups = uby_dups[uby_dups['Phrase'].duplicated(keep=False)]\n",
    "uby_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f790ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context free             46\n",
       "high level               42\n",
       "programming language     42\n",
       "natural language         41\n",
       "pattern recognition      41\n",
       "programming languages    41\n",
       "data structures          41\n",
       "sufficient conditions    39\n",
       "data structure           39\n",
       "problem solving          39\n",
       "Name: Phrase, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uby_dups['Phrase'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2507595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991,\n",
       "       1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
       "       2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n",
       "       2015, 2016, 2017], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uby_dups[uby_dups['Phrase'] == 'image processing']['Year'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569dc04f",
   "metadata": {},
   "source": [
    "# Phrase matching/similarity for input papers (title + abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "466ead01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an input paper (title + abstract), extract the phrases within it and return the\n",
    "# similar phrases found in the AutoPhrase results.\n",
    "# Can use Levenshtein distance to find similar strings, or just use direct phrase matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eb64645",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fp = '../data/arxiv/csv/2016.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e407bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sequential Short-Text Classification with Recu...</td>\n",
       "      <td>Recent approaches based on artificial neural n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiresolution Recurrent Neural Networks An A...</td>\n",
       "      <td>We introduce the multiresolution recurrent neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Document Image Coding and Clustering for Scrip...</td>\n",
       "      <td>The paper introduces a new method for discrimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tutorial on Answering Questions about Images w...</td>\n",
       "      <td>Together with the development of more accurate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Building Machines That Learn and Think Like Pe...</td>\n",
       "      <td>Recent progress in artificial intelligence AI ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Sequential Short-Text Classification with Recu...   \n",
       "1  Multiresolution Recurrent Neural Networks An A...   \n",
       "2  Document Image Coding and Clustering for Scrip...   \n",
       "3  Tutorial on Answering Questions about Images w...   \n",
       "4  Building Machines That Learn and Think Like Pe...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Recent approaches based on artificial neural n...  \n",
       "1  We introduce the multiresolution recurrent neu...  \n",
       "2  The paper introduces a new method for discrimi...  \n",
       "3  Together with the development of more accurate...  \n",
       "4  Recent progress in artificial intelligence AI ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_fp)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7399da88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sequential Short-Text Classification with Recurrent and Convolutional  Neural Networks Recent approaches based on artificial neural networks ANNs have shownpromising results for short-text classification However many short textsoccur in sequences eg sentences in a document or utterances in a dialogand most existing ANN-based systems do not leverage the preceding short textswhen classifying a subsequent one In this work we present a model based onrecurrent neural networks and convolutional neural networks that incorporatesthe preceding short texts Our model achieves state-of-the-art results on threedifferent datasets for dialog act prediction'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Title'][0] + ' ' + test_data['Abstract'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3240b32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.946833</td>\n",
       "      <td>context free</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.890167</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.909000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.896000</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.993000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238718</th>\n",
       "      <td>0.600501</td>\n",
       "      <td>practical implementation</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238719</th>\n",
       "      <td>0.600363</td>\n",
       "      <td>next generation</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238720</th>\n",
       "      <td>0.600185</td>\n",
       "      <td>deep convolutional neural</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238721</th>\n",
       "      <td>0.600087</td>\n",
       "      <td>network nodes</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238722</th>\n",
       "      <td>0.600061</td>\n",
       "      <td>received signal</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238701 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality                     Phrase  Year\n",
       "20            0.946833               context free  1968\n",
       "21            0.890167               time sharing  1968\n",
       "22            0.909000               context free  1969\n",
       "23            0.896000               time sharing  1969\n",
       "24            0.993000               context free  1970\n",
       "...                ...                        ...   ...\n",
       "238718        0.600501   practical implementation  2017\n",
       "238719        0.600363            next generation  2017\n",
       "238720        0.600185  deep convolutional neural  2017\n",
       "238721        0.600087              network nodes  2017\n",
       "238722        0.600061            received signal  2017\n",
       "\n",
       "[238701 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c68c8c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_phrase = 'convolutional neural networks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2850fb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20         True\n",
       "21        False\n",
       "22         True\n",
       "23        False\n",
       "24         True\n",
       "          ...  \n",
       "238718    False\n",
       "238719    False\n",
       "238720    False\n",
       "238721    False\n",
       "238722    False\n",
       "Length: 238701, dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ix = uby.apply(lambda x: x['Phrase'][0] == 'c' if isinstance(x['Phrase'], str) else False, axis=1)\n",
    "valid_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c92bab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['context free', 'computer science', 'computer graphics', ...,\n",
       "       'complete characterization', 'co occurrence matrix',\n",
       "       'computational approach'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_phrases = uby[valid_ix]['Phrase'].unique()\n",
    "unique_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1e3a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = ''\n",
    "dist = float('inf')\n",
    "for phrase in unique_phrases:\n",
    "    diff = Lv.distance(input_phrase, phrase)\n",
    "    if diff < dist:\n",
    "        candidate = phrase\n",
    "        dist = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1806a7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'convolutional neural networks'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "747af00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "628e5e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136900</th>\n",
       "      <td>0.865809</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152925</th>\n",
       "      <td>0.915629</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172010</th>\n",
       "      <td>0.937014</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190695</th>\n",
       "      <td>0.931728</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212473</th>\n",
       "      <td>0.917273</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233574</th>\n",
       "      <td>0.904261</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality                         Phrase  Year\n",
       "136900        0.865809  convolutional neural networks  2012\n",
       "152925        0.915629  convolutional neural networks  2013\n",
       "172010        0.937014  convolutional neural networks  2014\n",
       "190695        0.931728  convolutional neural networks  2015\n",
       "212473        0.917273  convolutional neural networks  2016\n",
       "233574        0.904261  convolutional neural networks  2017"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uby[uby['Phrase'] == 'convolutional neural networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a41c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same approach, but keeping track of all candidates this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5049a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for phrase in unique_phrases:\n",
    "    dist = Lv.distance(input_phrase, phrase)\n",
    "    candidates.append((dist, phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b5cda7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7587a8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'convolutional neural networks'),\n",
       " (1, 'convolutional neural network'),\n",
       " (3, 'convolution neural network'),\n",
       " (4, 'convolutional neural network cnn'),\n",
       " (4, 'convolutional neural networks cnn'),\n",
       " (5, 'convolutional neural networks cnns'),\n",
       " (7, 'convolutional networks'),\n",
       " (8, 'convolutional network'),\n",
       " (9, 'cellular neural networks'),\n",
       " (9, 'chaotic neural networks')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faee5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using df.apply so we can look at all phrases, not just phrases that start with the same letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "409b65d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "      <th>Dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.946833</td>\n",
       "      <td>context free</td>\n",
       "      <td>1968</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.890167</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1968</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.909000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1969</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.896000</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1969</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.993000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1970</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238718</th>\n",
       "      <td>0.600501</td>\n",
       "      <td>practical implementation</td>\n",
       "      <td>2017</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238719</th>\n",
       "      <td>0.600363</td>\n",
       "      <td>next generation</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238720</th>\n",
       "      <td>0.600185</td>\n",
       "      <td>deep convolutional neural</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238721</th>\n",
       "      <td>0.600087</td>\n",
       "      <td>network nodes</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238722</th>\n",
       "      <td>0.600061</td>\n",
       "      <td>received signal</td>\n",
       "      <td>2017</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238701 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality                     Phrase  Year  Dist\n",
       "20            0.946833               context free  1968    22\n",
       "21            0.890167               time sharing  1968    24\n",
       "22            0.909000               context free  1969    22\n",
       "23            0.896000               time sharing  1969    24\n",
       "24            0.993000               context free  1970    22\n",
       "...                ...                        ...   ...   ...\n",
       "238718        0.600501   practical implementation  2017    22\n",
       "238719        0.600363            next generation  2017    21\n",
       "238720        0.600185  deep convolutional neural  2017    14\n",
       "238721        0.600087              network nodes  2017    21\n",
       "238722        0.600061            received signal  2017    25\n",
       "\n",
       "[238701 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uby_test = uby.copy()\n",
    "uby_test['Dist'] = uby_test.apply(lambda x: Lv.distance(input_phrase, x['Phrase']) if isinstance(x['Phrase'], str) else float('inf'), axis=1)\n",
    "uby_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3219a42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "      <th>Dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212473</th>\n",
       "      <td>0.917273</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233574</th>\n",
       "      <td>0.904261</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152925</th>\n",
       "      <td>0.915629</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190695</th>\n",
       "      <td>0.931728</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136900</th>\n",
       "      <td>0.865809</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172010</th>\n",
       "      <td>0.937014</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190443</th>\n",
       "      <td>0.936880</td>\n",
       "      <td>convolutional neural network</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174069</th>\n",
       "      <td>0.898522</td>\n",
       "      <td>convolutional neural network</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212157</th>\n",
       "      <td>0.922546</td>\n",
       "      <td>convolutional neural network</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153942</th>\n",
       "      <td>0.900172</td>\n",
       "      <td>convolutional neural network</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality                         Phrase  Year  Dist\n",
       "212473        0.917273  convolutional neural networks  2016     0\n",
       "233574        0.904261  convolutional neural networks  2017     0\n",
       "152925        0.915629  convolutional neural networks  2013     0\n",
       "190695        0.931728  convolutional neural networks  2015     0\n",
       "136900        0.865809  convolutional neural networks  2012     0\n",
       "172010        0.937014  convolutional neural networks  2014     0\n",
       "190443        0.936880   convolutional neural network  2015     1\n",
       "174069        0.898522   convolutional neural network  2014     1\n",
       "212157        0.922546   convolutional neural network  2016     1\n",
       "153942        0.900172   convolutional neural network  2013     1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uby_test.sort_values('Dist')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a83a81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on the unique overall df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91f00f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un_all_test = un_all.copy()\n",
    "# un_all_test['Dist'] = un_all_test.apply(lambda x: Lv.distance(input_phrase, x['Phrase']) if isinstance(x['Phrase'], str) else float('inf'), axis=1)\n",
    "# un_all_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e271bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#un_all_test.sort_values('Dist')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f987790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidating results\n",
    "# Can start with the most common phrases and change phrases that are close enough (distance <= 5?)\n",
    "uby_counts = uby.groupby('Phrase').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b01c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_years tells us how many years the phrase has shown up in\n",
    "uby['num_years'] = uby.apply(lambda x: uby_counts[x['Phrase']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ab02301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "      <th>num_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.946833</td>\n",
       "      <td>context free</td>\n",
       "      <td>1968</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.890167</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.909000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1969</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.896000</td>\n",
       "      <td>time sharing</td>\n",
       "      <td>1969</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.993000</td>\n",
       "      <td>context free</td>\n",
       "      <td>1970</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Phrase Quality        Phrase  Year  num_years\n",
       "20        0.946833  context free  1968         46\n",
       "21        0.890167  time sharing  1968          2\n",
       "22        0.909000  context free  1969         46\n",
       "23        0.896000  time sharing  1969          2\n",
       "24        0.993000  context free  1970         46"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uby.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044fc25b",
   "metadata": {},
   "source": [
    "# Model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "728ff2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: Phrase, Phrase Quality, num_years\n",
    "# Phrase needs to be one hot encoded\n",
    "# y: Only the year (may need to use the unique overall dataframe?)\n",
    "\n",
    "# For phrase quality - standard scaler by year?\n",
    "# For num_years - normalize overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e81f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_pipe = Pipeline([('scale', StandardScaler())])\n",
    "ohe_pipe = Pipeline([('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "ct = ColumnTransformer(transformers=[('ohe', ohe_pipe, ['Phrase']),\n",
    "                                     ('scale', std_pipe, ['num_years']),\n",
    "                                    ('keep', 'passthrough', ['Phrase Quality'])])\n",
    "pl = Pipeline([('transform', ct), ('classifier', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8981b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "X_train, X_test, y_train, y_test = train_test_split(uby[['Phrase', 'num_years', 'Phrase Quality']],\n",
    "                                                    uby['Year'],\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6464599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c570563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean accuracy - 8% accurate\n",
    "# pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3cdc2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['Predicted Year'] = pl.predict(X_test)\n",
    "# X_test['Year'] = y_test\n",
    "# X_test['Abs Year Diff'] = abs(X_test['Year'] - X_test['Predicted Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d61ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test['Abs Year Diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39655f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THINGS TO TEST:\n",
    "# Using the unique by year dataframe, then only keeping one instance of duplicate phrases\n",
    "# but replace the year with the average (or median) of the years\n",
    "# Normalizing the numeric features\n",
    "\n",
    "# Try using phrasal segmentation model to run on a single paper title + abstract\n",
    "# Or a single paper full paper text\n",
    "\n",
    "# Try grouping by papers by a range of years (maybe 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "172552bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train[X_train['Phrase']=='convolutional neural networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddf10e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.DataFrame([[1.0, 'convolutional neural networks', 2005, 6]], columns=['Phrase Quality', 'Phrase', 'Year', 'num_years'])\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44d83a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.predict(test[['Phrase', 'num_years', 'Phrase Quality']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b451fc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "      <th>num_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136900</th>\n",
       "      <td>0.865809</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152925</th>\n",
       "      <td>0.915629</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172010</th>\n",
       "      <td>0.937014</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190695</th>\n",
       "      <td>0.931728</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212473</th>\n",
       "      <td>0.917273</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233574</th>\n",
       "      <td>0.904261</td>\n",
       "      <td>convolutional neural networks</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality                         Phrase  Year  num_years\n",
       "136900        0.865809  convolutional neural networks  2012          6\n",
       "152925        0.915629  convolutional neural networks  2013          6\n",
       "172010        0.937014  convolutional neural networks  2014          6\n",
       "190695        0.931728  convolutional neural networks  2015          6\n",
       "212473        0.917273  convolutional neural networks  2016          6\n",
       "233574        0.904261  convolutional neural networks  2017          6"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uby[uby['Phrase'] == 'convolutional neural networks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d947ff",
   "metadata": {},
   "source": [
    "# Baseline model testing with grouped phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "390a3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fae5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../results/dblp-v10-grouped/phrases.csv', index_col=0)\n",
    "df = df[4:]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a57893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_years is slightly different since we grouped years now\n",
    "phr_counts = df.groupby('Phrase').size()\n",
    "df['num_years'] = df.apply(lambda x: phr_counts[x['Phrase']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19b3250c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "      <th>Num Words</th>\n",
       "      <th>num_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.98100</td>\n",
       "      <td>tunnel diode</td>\n",
       "      <td>1960-1964</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.92850</td>\n",
       "      <td>differential equations</td>\n",
       "      <td>1960-1964</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.89700</td>\n",
       "      <td>high speed</td>\n",
       "      <td>1960-1964</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.88400</td>\n",
       "      <td>data processing</td>\n",
       "      <td>1960-1964</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.55575</td>\n",
       "      <td>per cent</td>\n",
       "      <td>1960-1964</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Phrase Quality                  Phrase       Year  Num Words  num_years\n",
       "4         0.98100            tunnel diode  1960-1964          2          1\n",
       "5         0.92850  differential equations  1960-1964          2         12\n",
       "6         0.89700              high speed  1960-1964          2         12\n",
       "7         0.88400         data processing  1960-1964          2         12\n",
       "8         0.55575                per cent  1960-1964          2          5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63d60a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pipe = Pipeline([('scale', StandardScaler())])\n",
    "ohe_pipe = Pipeline([('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "ct = ColumnTransformer(transformers=[('ohe', ohe_pipe, ['Phrase']),\n",
    "                                     ('scale', std_pipe, ['num_years']),\n",
    "                                    ('keep', 'passthrough', ['Phrase Quality'])])\n",
    "pl = Pipeline([('transform', ct), ('classifier', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3e655e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['Phrase', 'num_years', 'Phrase Quality']],\n",
    "                                                    df['Year'],\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adf64b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6231af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 42.5% accuracy\n",
    "# pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6869eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['Predicted Year'] = pl.predict(X_test)\n",
    "# X_test['Year'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9571340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the accuracy compare to just guessing the most common?\n",
    "#X_test['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ccb05f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(y_test == '2010-2014').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ae257",
   "metadata": {},
   "source": [
    "# Refined model - only using grouped phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b44b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential other classifiers to use\n",
    "# K nearest neighbor\n",
    "# Naive Bayes\n",
    "# Linear Discriminant\n",
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1846d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../results/dblp-v10-grouped/phrases.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da65e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_years is slightly different since we grouped years now\n",
    "phr_counts = df.groupby('Phrase').size()\n",
    "df['num_years'] = df.apply(lambda x: phr_counts[x['Phrase']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dcc0c095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "      <th>Num Words</th>\n",
       "      <th>num_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991500</td>\n",
       "      <td>operations research</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.650500</td>\n",
       "      <td>operations research society of america</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.573500</td>\n",
       "      <td>high speed</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525500</td>\n",
       "      <td>operations research society</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981000</td>\n",
       "      <td>tunnel diode</td>\n",
       "      <td>1960-1964</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303923</th>\n",
       "      <td>0.500036</td>\n",
       "      <td>target sites</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303924</th>\n",
       "      <td>0.500033</td>\n",
       "      <td>biological information</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303925</th>\n",
       "      <td>0.500027</td>\n",
       "      <td>non cooperative game</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303926</th>\n",
       "      <td>0.500012</td>\n",
       "      <td>coding technique</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303927</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>language features</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303928 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality                                  Phrase       Year  \\\n",
       "0             0.991500                     operations research  1950-1959   \n",
       "1             0.650500  operations research society of america  1950-1959   \n",
       "2             0.573500                              high speed  1950-1959   \n",
       "3             0.525500             operations research society  1950-1959   \n",
       "4             0.981000                            tunnel diode  1960-1964   \n",
       "...                ...                                     ...        ...   \n",
       "303923        0.500036                            target sites  2015-2017   \n",
       "303924        0.500033                  biological information  2015-2017   \n",
       "303925        0.500027                    non cooperative game  2015-2017   \n",
       "303926        0.500012                        coding technique  2015-2017   \n",
       "303927        0.500004                       language features  2015-2017   \n",
       "\n",
       "        Num Words  num_years  \n",
       "0               2         10  \n",
       "1               5          1  \n",
       "2               2         13  \n",
       "3               3          1  \n",
       "4               2          1  \n",
       "...           ...        ...  \n",
       "303923          2          3  \n",
       "303924          2          4  \n",
       "303925          3          3  \n",
       "303926          2          6  \n",
       "303927          2          6  \n",
       "\n",
       "[303928 rows x 5 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9b694ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    204289\n",
       "3     45174\n",
       "1     39275\n",
       "4     11557\n",
       "5      2772\n",
       "6       861\n",
       "Name: Num Words, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Num Words'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "227b0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['Phrase', 'num_years', 'Phrase Quality', 'Num Words']],\n",
    "                                                    df['Year'])\n",
    "                                                    #random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c4a1fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6d215a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pipe = Pipeline([('scale', StandardScaler())])\n",
    "ohe_pipe = Pipeline([('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "ct = ColumnTransformer(transformers=[('ohe', ohe_pipe, ['Phrase']),\n",
    "                                     ('scale', std_pipe, ['num_years', 'Num Words', 'Phrase Quality']),\n",
    "                                    ('keep', 'passthrough', ['Phrase Quality'])])\n",
    "pl = Pipeline([('transform', ct), ('classifier', AdaBoostClassifier(n_estimators=100, learning_rate=1.1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "990dacec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transform',\n",
       "                 ColumnTransformer(transformers=[('ohe',\n",
       "                                                  Pipeline(steps=[('one-hot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Phrase']),\n",
       "                                                 ('scale',\n",
       "                                                  Pipeline(steps=[('scale',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['num_years', 'Num Words',\n",
       "                                                   'Phrase Quality']),\n",
       "                                                 ('keep', 'passthrough',\n",
       "                                                  ['Phrase Quality'])])),\n",
       "                ('classifier',\n",
       "                 AdaBoostClassifier(learning_rate=1.1, n_estimators=100))])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c34e51fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3563080729646495"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.339 with DecisionTreeClassifier\n",
    "# RandomForest took too long to train\n",
    "# 0.353 with AdaBoostClassifier\n",
    "# 0.356 with n_estimators 80, learning_rate 1.1\n",
    "pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5d60575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3530704640572767"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy to beat: 0.353 (if we just guessed the most common year label)\n",
    "(y_test == '2010-2014').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ff8f2",
   "metadata": {},
   "source": [
    "## Testing with new segmentation results - may not be very effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4975aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes the new segmentation csvs (high quality phrases, no duplicates)\n",
    "infolder = '../results/test'\n",
    "subfolders = glob(infolder + '/*.csv')\n",
    "#subfolders = list(filter(lambda x: 'segmented' in x, subfolders))\n",
    "data = pd.DataFrame(columns=['Phrases', 'Year Range'])\n",
    "for fp in subfolders:\n",
    "    df = pd.read_csv(fp, index_col=0)\n",
    "    df = df.dropna()\n",
    "    #df['Num Phrases'] = df.apply(lambda x: len(x['Phrases'].split(',')), axis=1)\n",
    "    #df = df.drop('Phrases', axis=1)\n",
    "    data = data.append(df, ignore_index=True)\n",
    "data = data.dropna()\n",
    "data['Phrases'] = data['Phrases'].map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51d6869b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010-2014    872482\n",
       "2005-2009    651795\n",
       "2015-2017    429999\n",
       "2000-2004    309058\n",
       "1995-1999    143710\n",
       "1990-1994     70637\n",
       "1985-1989     31911\n",
       "1980-1984     16063\n",
       "1975-1979      8794\n",
       "1970-1974      5133\n",
       "1965-1969      2507\n",
       "1960-1964       807\n",
       "1950-1959       323\n",
       "Name: Year Range, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Year Range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "254a8f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "      <th>Year Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[triangle, wheatstone, bridge, tangent]</td>\n",
       "      <td>1950-1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[computable, differential equations, numerical...</td>\n",
       "      <td>1950-1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fur]</td>\n",
       "      <td>1950-1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[amplifiers, electronic, computing]</td>\n",
       "      <td>1950-1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[society, operations research, america, journal]</td>\n",
       "      <td>1950-1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543214</th>\n",
       "      <td>[research, computational burden, inertial navi...</td>\n",
       "      <td>2015-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543215</th>\n",
       "      <td>[media, women, innovation, eliminating, gender...</td>\n",
       "      <td>2015-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543216</th>\n",
       "      <td>[batch, inventory, dynamic pricing, infinite h...</td>\n",
       "      <td>2015-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543217</th>\n",
       "      <td>[poly, imager, earth, khz, m 1, clock, cmos, m...</td>\n",
       "      <td>2015-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543218</th>\n",
       "      <td>[research, water, temperature rise, net, worki...</td>\n",
       "      <td>2015-2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2543219 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Phrases Year Range\n",
       "0                  [triangle, wheatstone, bridge, tangent]  1950-1959\n",
       "1        [computable, differential equations, numerical...  1950-1959\n",
       "2                                                    [fur]  1950-1959\n",
       "3                      [amplifiers, electronic, computing]  1950-1959\n",
       "4         [society, operations research, america, journal]  1950-1959\n",
       "...                                                    ...        ...\n",
       "2543214  [research, computational burden, inertial navi...  2015-2017\n",
       "2543215  [media, women, innovation, eliminating, gender...  2015-2017\n",
       "2543216  [batch, inventory, dynamic pricing, infinite h...  2015-2017\n",
       "2543217  [poly, imager, earth, khz, m 1, clock, cmos, m...  2015-2017\n",
       "2543218  [research, water, temperature rise, net, worki...  2015-2017\n",
       "\n",
       "[2543219 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d820231b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "      <th>Year Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1240738</th>\n",
       "      <td>[purpose, as, net, basic, an empirical study, ...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240739</th>\n",
       "      <td>[research, as, specialist, reconstruction, tes...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240740</th>\n",
       "      <td>[as, visual, analyzing, f, identifying, backgr...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240741</th>\n",
       "      <td>[optimal, as, recent years, pedestrian navigat...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240742</th>\n",
       "      <td>[as, master secret, composite order, doi, stan...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113215</th>\n",
       "      <td>[as, multi, comparison, china, understanding, ...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113216</th>\n",
       "      <td>[as, simultaneous, reactive, wide spectrum, ne...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113217</th>\n",
       "      <td>[schwartz, as, condorcet, visualization, proto...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113218</th>\n",
       "      <td>[axiomatization, expected regret, decision mak...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113219</th>\n",
       "      <td>[stem, combining, search, perspective, truth, ...</td>\n",
       "      <td>2010-2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>872482 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Phrases Year Range\n",
       "1240738  [purpose, as, net, basic, an empirical study, ...  2010-2014\n",
       "1240739  [research, as, specialist, reconstruction, tes...  2010-2014\n",
       "1240740  [as, visual, analyzing, f, identifying, backgr...  2010-2014\n",
       "1240741  [optimal, as, recent years, pedestrian navigat...  2010-2014\n",
       "1240742  [as, master secret, composite order, doi, stan...  2010-2014\n",
       "...                                                    ...        ...\n",
       "2113215  [as, multi, comparison, china, understanding, ...  2010-2014\n",
       "2113216  [as, simultaneous, reactive, wide spectrum, ne...  2010-2014\n",
       "2113217  [schwartz, as, condorcet, visualization, proto...  2010-2014\n",
       "2113218  [axiomatization, expected regret, decision mak...  2010-2014\n",
       "2113219  [stem, combining, search, perspective, truth, ...  2010-2014\n",
       "\n",
       "[872482 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Year Range'] == '2010-2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "42f8a12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "      <th>Num Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178384</th>\n",
       "      <td>0.818842</td>\n",
       "      <td>as</td>\n",
       "      <td>2010-2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality Phrase       Year  Num Words\n",
       "178384        0.818842     as  2010-2014          1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases[phrases['Phrase']=='as']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "166e2b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase Quality</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Year</th>\n",
       "      <th>Num Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991500</td>\n",
       "      <td>operations research</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.650500</td>\n",
       "      <td>operations research society of america</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.573500</td>\n",
       "      <td>high speed</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525500</td>\n",
       "      <td>operations research society</td>\n",
       "      <td>1950-1959</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981000</td>\n",
       "      <td>tunnel diode</td>\n",
       "      <td>1960-1964</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303923</th>\n",
       "      <td>0.500036</td>\n",
       "      <td>target sites</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303924</th>\n",
       "      <td>0.500033</td>\n",
       "      <td>biological information</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303925</th>\n",
       "      <td>0.500027</td>\n",
       "      <td>non cooperative game</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303926</th>\n",
       "      <td>0.500012</td>\n",
       "      <td>coding technique</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303927</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>language features</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303928 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Phrase Quality                                  Phrase       Year  \\\n",
       "0             0.991500                     operations research  1950-1959   \n",
       "1             0.650500  operations research society of america  1950-1959   \n",
       "2             0.573500                              high speed  1950-1959   \n",
       "3             0.525500             operations research society  1950-1959   \n",
       "4             0.981000                            tunnel diode  1960-1964   \n",
       "...                ...                                     ...        ...   \n",
       "303923        0.500036                            target sites  2015-2017   \n",
       "303924        0.500033                  biological information  2015-2017   \n",
       "303925        0.500027                    non cooperative game  2015-2017   \n",
       "303926        0.500012                        coding technique  2015-2017   \n",
       "303927        0.500004                       language features  2015-2017   \n",
       "\n",
       "        Num Words  \n",
       "0               2  \n",
       "1               5  \n",
       "2               2  \n",
       "3               3  \n",
       "4               2  \n",
       "...           ...  \n",
       "303923          2  \n",
       "303924          2  \n",
       "303925          3  \n",
       "303926          2  \n",
       "303927          2  \n",
       "\n",
       "[303928 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "75f5d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['Phrases']],\n",
    "                                                    data['Year Range'],\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0d8964d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c93fa692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2223922    [host language, multiple target, ruby, compile...\n",
       "1851609    [fading multiple access, full csi, eavesdroppe...\n",
       "1311483    [adapting, imager, as, lung cancer, localizati...\n",
       "1555840    [prediction, as, a case study, potential benef...\n",
       "553527     [innovation, nyquist rate, digital, nyquist, p...\n",
       "                                 ...                        \n",
       "2484129    [018m cmos technology, capacitive, rms, ota, d...\n",
       "817212     [access edca, ieee, ieee 80211e, quality of se...\n",
       "2175372    [object appearance, tracker, inspired approach...\n",
       "971005     [bridge, analyzing, learning, data gathering, ...\n",
       "1696727    [video, perfectly matched, previously proposed...\n",
       "Name: Phrases, Length: 635805, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "90f400eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[list(['host language', 'multiple target', 'ruby', 'compiler', 'execution environments', 'compilation', 'virtual machine', 'python', 'task migration', 'ideally', 'javascript', 'java', 'web applications', 'cultural', 'execution speed', 'php', 'orders of magnitude faster'])\n list(['fading multiple access', 'full csi', 'eavesdropper', 'onoff', 'wt', 'channel state information csi', 'wire', 'employing', 'intended receiver', 'csi', 'if', 'eve', 'snr', 'do', 'eavesdropper eve', 'easily computable', 'power control', 'optimal power control', 'sum rate', 'next', 'achievable secrecy', 'cooperative jamming', 'mac'])\n list(['adapting', 'imager', 'as', 'lung cancer', 'localization', 'lung', 'gpu', 'tracking', 'image reconstruction', 'tumor', 'real time', 'radiotherapy', 'principal component analysis', 'nvidia', 'reconstructed image', 'c1060', 'pca', 'first', 'clinical application', 'reference image', 'digital', 'projection based', 'vector fields', 'mm', 'phantom', 'reconstructing', 'accurate', 'patient data'])\n ...\n list(['object appearance', 'tracker', 'inspired approach', 'object tracking', 'ransac', 'cognitive psychology', 'extensively evaluated', 'keypoint', 'correlation filter', 'dual', 'art', 'partial occlusion', 'tracked object', 'additional information'])\n list(['bridge', 'analyzing', 'learning', 'data gathering', 'proposed approach', 'governor', 'situated', 'network interfaces', 'home automation', 'power line communication', 'home gateway', 'home', 'hierarchical', 'proposed framework', 'control protocol', 'top', 'upnp', 'global', 'multi'])\n list(['video', 'perfectly matched', 'previously proposed', 'as', 'visual', 'identification', 'i', 'cognizant', 'user study', 'video streaming', 'so', 'visually salient', 'forward error correction', 'loop', 'error concealment', 'lr', 'if', 'side information', 'roi', 'overall', 'concealed', 'streaming video', 'replacement', 'first', 'fec', 'increased dramatically', 'uep', 'regularization', 'low saliency', 'concealment', 'unequal error protection uep scheme', 'block', 'subjective quality', 'psnr', 'saliency', 'ii', 'hr'])].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24108/1641781809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Phrases'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \"\"\"\n\u001b[0;32m    487\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \"\"\"\n\u001b[0;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown, force_all_finite)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         X_list, n_samples, n_features = self._check_X(\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X, force_all_finite)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ndim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m# if not a dataframe, do normal check_array validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mX_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    762\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[list(['host language', 'multiple target', 'ruby', 'compiler', 'execution environments', 'compilation', 'virtual machine', 'python', 'task migration', 'ideally', 'javascript', 'java', 'web applications', 'cultural', 'execution speed', 'php', 'orders of magnitude faster'])\n list(['fading multiple access', 'full csi', 'eavesdropper', 'onoff', 'wt', 'channel state information csi', 'wire', 'employing', 'intended receiver', 'csi', 'if', 'eve', 'snr', 'do', 'eavesdropper eve', 'easily computable', 'power control', 'optimal power control', 'sum rate', 'next', 'achievable secrecy', 'cooperative jamming', 'mac'])\n list(['adapting', 'imager', 'as', 'lung cancer', 'localization', 'lung', 'gpu', 'tracking', 'image reconstruction', 'tumor', 'real time', 'radiotherapy', 'principal component analysis', 'nvidia', 'reconstructed image', 'c1060', 'pca', 'first', 'clinical application', 'reference image', 'digital', 'projection based', 'vector fields', 'mm', 'phantom', 'reconstructing', 'accurate', 'patient data'])\n ...\n list(['object appearance', 'tracker', 'inspired approach', 'object tracking', 'ransac', 'cognitive psychology', 'extensively evaluated', 'keypoint', 'correlation filter', 'dual', 'art', 'partial occlusion', 'tracked object', 'additional information'])\n list(['bridge', 'analyzing', 'learning', 'data gathering', 'proposed approach', 'governor', 'situated', 'network interfaces', 'home automation', 'power line communication', 'home gateway', 'home', 'hierarchical', 'proposed framework', 'control protocol', 'top', 'upnp', 'global', 'multi'])\n list(['video', 'perfectly matched', 'previously proposed', 'as', 'visual', 'identification', 'i', 'cognizant', 'user study', 'video streaming', 'so', 'visually salient', 'forward error correction', 'loop', 'error concealment', 'lr', 'if', 'side information', 'roi', 'overall', 'concealed', 'streaming video', 'replacement', 'first', 'fec', 'increased dramatically', 'uep', 'regularization', 'low saliency', 'concealment', 'unequal error protection uep scheme', 'block', 'subjective quality', 'psnr', 'saliency', 'ii', 'hr'])].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "ohe.fit_transform(X_test['Phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa24147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f6da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0c204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.fit(X_test['Phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65411eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0 1', '0 1n', '000 000', ..., 'zy', 'zynq', 'zynq soc'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575c254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95059"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6c3fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 225. GiB for an array with shape (635805, 95059) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17380/3212969305.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Phrases'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m             \u001b[0myt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 225. GiB for an array with shape (635805, 95059) and data type int32"
     ]
    }
   ],
   "source": [
    "mlb.fit_transform(X_test['Phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70299f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2223922    [host language, multiple target, ruby, compile...\n",
       "1851609    [fading multiple access, full csi, eavesdroppe...\n",
       "1311483    [adapting, imager, as, lung cancer, localizati...\n",
       "1555840    [prediction, as, a case study, potential benef...\n",
       "553527     [innovation, nyquist rate, digital, nyquist, p...\n",
       "                                 ...                        \n",
       "2484129    [018m cmos technology, capacitive, rms, ota, d...\n",
       "817212     [access edca, ieee, ieee 80211e, quality of se...\n",
       "2175372    [object appearance, tracker, inspired approach...\n",
       "971005     [bridge, analyzing, learning, data gathering, ...\n",
       "1696727    [video, perfectly matched, previously proposed...\n",
       "Name: Phrases, Length: 635805, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pipe = Pipeline([('scale', StandardScaler())])\n",
    "ohe_pipe = Pipeline([('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "ct = ColumnTransformer(transformers=[('ohe', ohe_pipe, ['Phrases']),\n",
    "                                     ('scale', std_pipe, ['Num Phrases'])\n",
    "                                    ])\n",
    "pl = Pipeline([('transform', ct), ('classifier', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc3785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206abdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
